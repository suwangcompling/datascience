{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# MapReduce in Word Counting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import urllib, string, random\n",
    "from nltk import word_tokenize\n",
    "from collections import Counter\n",
    "from operator import itemgetter\n",
    "from collections import defaultdict\n",
    "from functools import partial\n",
    "from itertools import product\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0. Data: Alice's Adventure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "firehose = urllib.urlopen(url=\"http://www.gutenberg.org/cache/epub/11/pg11.txt\")\n",
    "documents = firehose.readlines()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Old Technique: Brute Force"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def word_count_old(documents):\n",
    "    return Counter(word for document in documents for word in word_tokenize(document))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 622 ms, sys: 10.5 ms, total: 633 ms\n",
      "Wall time: 630 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "countOld = word_count_old(documents)\n",
    "countOld = sorted([(word,count) for word,count in countOld.iteritems()], key=itemgetter(1), reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(',', 2565),\n",
       " ('the', 1675),\n",
       " (\"'\", 1130),\n",
       " ('.', 1101),\n",
       " ('and', 824),\n",
       " ('to', 791),\n",
       " ('a', 669),\n",
       " ('of', 602),\n",
       " ('it', 525),\n",
       " ('she', 506)]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "countOld[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. MapReduce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class MapReduceWC:\n",
    "    # NB: _.. methods are module-private, not imported when import *.py\n",
    "    # NB: __.. methods are class-private, not accessible.\n",
    "\n",
    "    def __init__(self, documents):\n",
    "        self.documents = documents\n",
    "        self.collector = defaultdict(list)\n",
    "    \n",
    "    def __wc_mapper(self, document):\n",
    "        # for each word in the document, lazy-return (word,1).\n",
    "        for word in word_tokenize(document):\n",
    "            yield (word,1)\n",
    "            \n",
    "    def __wc_reducer(self, word, counts):\n",
    "        # sum up the counts for a word.\n",
    "        yield (word, sum(counts))\n",
    "        \n",
    "    def word_count(self):\n",
    "        for document in self.documents:\n",
    "            for word,count in self.__wc_mapper(document):\n",
    "                self.collector[word].append(count)\n",
    "        return [output\n",
    "                for word,counts in self.collector.iteritems()\n",
    "                for output in self.__wc_reducer(word,counts)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 577 ms, sys: 37.3 ms, total: 614 ms\n",
      "Wall time: 588 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "mrwc = MapReduceWC(documents)\n",
    "countNew = mrwc.word_count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(',', 2565),\n",
       " ('the', 1675),\n",
       " (\"'\", 1130),\n",
       " ('.', 1101),\n",
       " ('and', 824),\n",
       " ('to', 791),\n",
       " ('a', 669),\n",
       " ('of', 602),\n",
       " ('it', 525),\n",
       " ('she', 506)]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "countNew = sorted(countNew, key=itemgetter(1), reverse=True)\n",
    "countNew[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Additional Benchmarking with Brown\n",
    "\n",
    "**NB: No performance difference with 1 machine. However MapReduce allows distributed computing.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from nltk.corpus import brown\n",
    "brownSents = [' '.join(sent) for sent in brown.sents()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(u'the', 62713), (u',', 58336), (u'.', 50270), (u'of', 36080), (u'and', 27915), (u'to', 25732), (u'a', 21888), (u'in', 19540), (u'that', 10328), (u'is', 10100)]\n",
      "CPU times: user 9.98 s, sys: 122 ms, total: 10.1 s\n",
      "Wall time: 10 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# OLD WORD COUNT METHOD\n",
    "countOld = word_count_old(brownSents)\n",
    "countOld = sorted([(word,count) for word,count in countOld.iteritems()], key=itemgetter(1), reverse=True)\n",
    "print countOld[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(u'the', 62713), (u',', 58336), (u'.', 50270), (u'of', 36080), (u'and', 27915), (u'to', 25732), (u'a', 21888), (u'in', 19540), (u'that', 10328), (u'is', 10100)]\n",
      "CPU times: user 9.97 s, sys: 117 ms, total: 10.1 s\n",
      "Wall time: 10 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# NEW WORD COUNT METHOD\n",
    "mrwc = MapReduceWC(brownSents)\n",
    "countNew = mrwc.word_count()\n",
    "countNew = sorted(countNew, key=itemgetter(1), reverse=True)\n",
    "print countNew[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MapReduce in General"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# GENERALIZED MAPREDUCE\n",
    "def map_reduce(inputs, mapper, reducer):\n",
    "    collector = defaultdict(list)\n",
    "    for inpt in inputs:\n",
    "        for key,value in mapper(inpt):\n",
    "            collector[key].append(value)\n",
    "    return [output\n",
    "            for key,values in collector.iteritems()\n",
    "            for output in reducer(key,values)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# GENERALIZED REDUCER\n",
    "def reduce_values_using(aggregation_fn, key, values):\n",
    "    yield (key, aggregation_fn(values))\n",
    "def values_reducer(aggregation_fn):\n",
    "    # turns a (values->output) aggregation function into a reducer: (key,values)->(key,output).\n",
    "    return partial(reduce_values_using, aggregation_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# CREATEING SPECIALIZED REDUCERS\n",
    "sum_reducer = values_reducer(sum)\n",
    "max_reducer = values_reducer(max)\n",
    "min_reducer = values_reducer(min)\n",
    "count_distinct_reduer = values_reducer(lambda values: len(set(values)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Application: Matrix Multiplication"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** a. Matrix Representation**\n",
    "\n",
    "* Instead of storing (sparse) matrices using list of lists, only store non-zero cells with their indices indicated (e.g. $(\"A\", i, j, value)$ for $A_{ij}$ if $A_{ij}\\neq 0$). \n",
    "\n",
    "** b. Efficient Computation Using Indices**\n",
    "\n",
    "* For $C = A\\cdot B$ a cell in matrix $C$, $C_{ik}$ is only related to $A_{ij}$ and $B_{jk}$.\n",
    "* In the following graph, $i$ and $k$ locate a cell in $C$ (i.e. $C_{ik}$), the column/row index of $A$/$B$, $j$, is used to indicate that these two cells \"meet\" in the computation.\n",
    "* Therefore, for a pair of element representation $(\"A\", i, j, value1)$ and $(\"B\", j, k, value2)$, we know extract $(i,k)$ to locate the cell $C_{ik}$, and use $j$ to indicate that these two cells meet in computation.\n",
    "* **NB:** In the following, $m$ is used *a la place de* $j$ for \"meet-index\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#   A_ij   B_jk\n",
    "#     ^^     ^^\n",
    "#     ||_____||\n",
    "#     |   |   |\n",
    "#     |\"meet\" |\n",
    "#     | index |\n",
    "#     |_______|\n",
    "#         |\n",
    "#        C_ik"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# MAPPER\n",
    "def matrix_multiply_mapper(m, element):\n",
    "    # m: the meet-index.\n",
    "    # element: (matrix-name, i, j, value).\n",
    "    name, i, j, value = element\n",
    "    if name==\"A\":\n",
    "        for k in range(m): # cuz A_ij is relevant for computing C_ik, k=1,..,m.\n",
    "            yield((i,k),(j,value)) # using A's col dimension for meet-indexing.\n",
    "    else:\n",
    "        for k in range(m):\n",
    "            yield((k,j),(i,value)) # using B's row dimension for meet-indexing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# REDUCER\n",
    "def matrix_multiply_reducer(m, key, indexedValues):\n",
    "    #                           ^         ^\n",
    "    #                           |         |\n",
    "    #   expect C's index (e.g. C_ik)    expect (meet-index, value)\n",
    "    resultsByIndex = defaultdict(list)\n",
    "    for index,value in indexedValues:\n",
    "        resultsByIndex[index].append(value)\n",
    "    sumProduct = sum(results[0]*results[1] \n",
    "                     for results in resultsByIndex.values() # results: [valFromA,valueFromB].\n",
    "                     if len(results)==2) # non-meet C_ik cells won't have two values appended.\n",
    "    if sumProduct!=0.0:\n",
    "        yield (key, sumProduct) # key: C's index (e.g. C_ik); sumProduct: C_ik's values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[((0, 1), -3), ((0, 0), 32)]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TEST ON TOY EXAMPLE\n",
    "entries = [(\"A\", 0, 0, 3), (\"A\", 0, 1, 2), (\"B\", 0, 0, 4), (\"B\", 0, 1, -1), (\"B\", 1, 0, 10)]\n",
    "mapper = partial(matrix_multiply_mapper, 3)\n",
    "reducer = partial(matrix_multiply_reducer, 3)\n",
    "map_reduce(entries, mapper, reducer)\n",
    "    # output in matrix rep.:\n",
    "    # [[32,-3, 0],\n",
    "    #  [ 0, 0, 0]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### C. Comparing Brute-Force Matrix Multiplication with MapReduce Version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# MATRIX CONVERTER\n",
    "#  [[..],[..],..] => [element0, element1, ..].\n",
    "def matrix_convert(M, matrixName=None):\n",
    "    if matrixName==None: # randomly generate matrix name: len5 alphanumeric.\n",
    "        matrixName=''.join(random.choice(string.ascii_uppercase + string.digits) for _ in range(5))\n",
    "    return [(matrixName, i, j, M[i][j]) for i in range(M.shape[0]) for j in range(M.shape[1]) if M[i][j]!=0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# SPARSE MATRIX GENERATOR\n",
    "def sparse_matrix(shape, prop=.1): # prop: proportion of 1's in distribution.\n",
    "    assert len(shape)==2\n",
    "    distr = list(np.repeat(0,int((1-prop)*10))) + list(np.repeat(1,int(prop*10)))\n",
    "    matrix = np.zeros(shape)\n",
    "    for i in range(shape[0]):\n",
    "        for j in range(shape[1]):\n",
    "            matrix[i][j] = random.choice(distr)\n",
    "    return matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('M', 0, 9, 1.0),\n",
       " ('M', 1, 5, 1.0),\n",
       " ('M', 1, 6, 1.0),\n",
       " ('M', 1, 8, 1.0),\n",
       " ('M', 2, 7, 1.0),\n",
       " ('M', 3, 4, 1.0),\n",
       " ('M', 3, 5, 1.0),\n",
       " ('M', 4, 0, 1.0),\n",
       " ('M', 5, 7, 1.0),\n",
       " ('M', 5, 9, 1.0),\n",
       " ('M', 6, 6, 1.0),\n",
       " ('M', 7, 2, 1.0),\n",
       " ('M', 8, 0, 1.0),\n",
       " ('M', 9, 1, 1.0),\n",
       " ('M', 9, 2, 1.0),\n",
       " ('M', 9, 5, 1.0)]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "M = sparse_matrix((10,10))\n",
    "matrix_convert(M,matrixName='M')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# BRUTE-FORCE MATRIX MULTIPLICATION\n",
    "def matrix_multiply(A,B):\n",
    "    assert type(A)==type(B)==np.ndarray # type checking.\n",
    "    assert A.shape[1]==B.shape[0] # dimension checking.\n",
    "    def sum_of_product(v,w):\n",
    "        assert len(v)==len(w)\n",
    "        total = 0\n",
    "        for i in range(len(v)):\n",
    "            total += v[i]*w[i]\n",
    "        return total\n",
    "    C = np.zeros((A.shape[0],B.shape[1]))\n",
    "    for i in range(A.shape[0]):\n",
    "        for j in range(B.shape[1]):\n",
    "            C[i][j] = sum_of_product(A[i],B[:,j])\n",
    "    return C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 77.5 ms, sys: 2.26 ms, total: 79.8 ms\n",
      "Wall time: 78.1 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "A = sparse_matrix((100,500))\n",
    "B = sparse_matrix((500,100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.62 s, sys: 6.25 ms, total: 1.63 s\n",
      "Wall time: 1.63 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 4.,  5.,  6., ...,  7.,  6.,  9.],\n",
       "       [ 5.,  4.,  2., ...,  4.,  5.,  9.],\n",
       "       [ 5.,  5.,  7., ...,  7.,  8.,  5.],\n",
       "       ..., \n",
       "       [ 4.,  5.,  2., ...,  9.,  2.,  2.],\n",
       "       [ 4.,  7.,  3., ...,  3.,  2.,  6.],\n",
       "       [ 3.,  5.,  4., ...,  4.,  2.,  0.]])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "matrix_multiply(A,B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "AConv = matrix_convert(A,matrixName='A')\n",
    "BConv = matrix_convert(B,matrixName='B')\n",
    "ABList = AConv+BConv\n",
    "mapper = partial(matrix_multiply_mapper, 500)\n",
    "reducer = partial(matrix_multiply_reducer, 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DONE\n",
      "CPU times: user 6.57 s, sys: 160 ms, total: 6.73 s\n",
      "Wall time: 6.71 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "map_reduce(ABList, mapper, reducer)\n",
    "print \"DONE\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Application: Building Cooccurrence & Similarity Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "stopwords = stopwords.words('english')\n",
    "from collections import defaultdict\n",
    "from functools import partial\n",
    "from itertools import permutations, product\n",
    "from string import punctuation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A. Load & Clean Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_wiki(cutoffFreq=50):\n",
    "    \n",
    "    print \"... extracting data\"\n",
    "    with open('/Users/jacobsw/Desktop/IMPLEMENTATION_CAMP/CODE/BASIC_TOPICS/DISTRIBUTIONAL_SEMANTICS/ASSIGNMENT_03/wikicorpus.txt','rb') as f:\n",
    "        raw = f.readlines()\n",
    "    raw = [sent.split() for sent in raw if sent.startswith('<c>')] \n",
    "        # extract sentences; split sentences into word complexes.\n",
    "    raw = [[map(partial(str.split, word), '|') for word in sent] for sent in raw] \n",
    "        # split word complexes into words.\n",
    "    \n",
    "    print \"... cleaning data\"\n",
    "    sents = [[word[0][1].lower() for word in sent if len(word[0])>1 \n",
    "              and word[0][2].startswith('N')\n",
    "              and word[0][1].lower() not in stopwords\n",
    "              and word[0][1] not in punctuation] for sent in raw]\n",
    "        # extract lemmas => complete sents corpus .\n",
    "    \n",
    "    print \"... building token list and vocabulary\"\n",
    "    tokens = [word for sent in sents for word in sent]\n",
    "        # type: list of words.\n",
    "    fdist = nltk.FreqDist(tokens)\n",
    "    vocab = list(set(tokens))   \n",
    "    \n",
    "    print \"... saving top %d-frequent in vocabulary\" % cutoffFreq\n",
    "    vocab = [word for word in vocab if fdist[word] >= cutoffFreq]\n",
    "        # vocab is not returned, because the k-frequent cut latter can change it.\n",
    "    sents = [[word.decode('utf-8','ignore') for word in sent if word in vocab] for sent in sents]\n",
    "        # type: list of lists of words.\n",
    "        \n",
    "    return sents\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "... extracting data\n",
      "... cleaning data\n",
      "... building token list and vocabulary\n",
      "... saving top 50-frequent in vocabulary\n"
     ]
    }
   ],
   "source": [
    "sents = load_wiki()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### B. Build Cooccurrence Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# MAPREDUCE FOR COOCCURRENCE TALLY\n",
    "def w2w_mapper(sent):\n",
    "    for w_i,w_j in product(sent,repeat=2):\n",
    "        yield (tuple(sorted((w_i,w_j))), 1)\n",
    "def w2w_reducer(pair, ocrs):\n",
    "    yield (pair, sum(ocrs))\n",
    "def w2w_mapreduce(sents):\n",
    "    collector = defaultdict(list)\n",
    "    for sent in sents:\n",
    "        for pair,count in w2w_mapper(sent):\n",
    "            collector[pair].append(count)\n",
    "    return [output\n",
    "            for pair,counts in collector.iteritems()\n",
    "            for output in w2w_reducer(pair,counts)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 27.3 s, sys: 479 ms, total: 27.8 s\n",
      "Wall time: 27.8 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "coocrList = w2w_mapreduce(sents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token Size: 5555152 | Vocab Size: 6969\n",
      "CPU times: user 3.73 s, sys: 67.6 ms, total: 3.8 s\n",
      "Wall time: 3.8 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "tokens = [pair for pair,_ in coocrList]\n",
    "tokens = [word for pair in tokens for word in pair]\n",
    "vocab = list(set(tokens))\n",
    "print \"Token Size: %d | Vocab Size: %d\" % (len(tokens),len(vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[((u'eugene', u'quality'), 6),\n",
       " ((u'california', u'pennant'), 2),\n",
       " ((u'jensen', u'people'), 6)]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coocrList[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "wordToIndex = {word:vocab.index(word) for word in vocab}\n",
    "indexToWord = {i:w for w,i in wordToIndex.iteritems()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# STORE (SPARSE) MATRIX IN COOCCURRENCE-ENTRIES LIST\n",
    "def sparse_cooccurrence_matrix(coocrList):\n",
    "    sparse = []\n",
    "    for (w_i,w_j),count in coocrList:\n",
    "        sparse += [('sp',wordToIndex[w_i],wordToIndex[w_j],count),\n",
    "                   ('sp',wordToIndex[w_j],wordToIndex[w_i],count)]\n",
    "    return sparse    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4.31 s, sys: 227 ms, total: 4.53 s\n",
      "Wall time: 4.52 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "sp = sparse_cooccurrence_matrix(coocrList)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### C. Build Similarity Matrix (Cosine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def matrix_normalize(sparse):\n",
    "    # generate ||v|| for each word.\n",
    "    wNorms = defaultdict(int)\n",
    "    for _,widx_i,widx_j,count in sparse:\n",
    "        wNorms[widx_i] += count**2\n",
    "    wNorms = {widx:np.sqrt(countSumSq) for widx,countSumSq in wNorms.iteritems()}\n",
    "    # normalize by (i,_) cell dividing ||v_i||.\n",
    "    for k,(spName,widx_i,widx_j,count) in enumerate(sparse):\n",
    "        sparse[k] = (spName,widx_i,widx_j,float(count)/wNorms[widx_i])\n",
    "    return sparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3.72 s, sys: 84.8 ms, total: 3.8 s\n",
      "Wall time: 3.8 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "spNorm = matrix_normalize(sp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.32 s, sys: 186 ms, total: 2.51 s\n",
      "Wall time: 2.51 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# NB: this is for MapReduce method.\n",
    "spNormT = [('spT',widx_j,widx_i,countNorm) for _,widx_i,widx_j,countNorm in spNorm]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### a. Method 1: To Numpy Matrix $\\Rightarrow$ Matrix Multiplication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.67 s, sys: 152 ms, total: 2.82 s\n",
      "Wall time: 2.8 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "spFullMatrixNorm = np.zeros((len(vocab),len(vocab)))\n",
    "for _,widx_i,widx_j,countNorm in spNorm:\n",
    "    spFullMatrixNorm[widx_i][widx_j] = countNorm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 19.9 s, sys: 133 ms, total: 20 s\n",
      "Wall time: 3.05 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "cosineSimMatrix = np.dot(spFullMatrixNorm, spFullMatrixNorm.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def cosine_similarity(w1, w2):\n",
    "    return cosineSimMatrix[wordToIndex[w1]][wordToIndex[w2]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.35866012820941412"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cosine_similarity('car','bugatti')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### b. Method 2: MapReduce (current takes ages w/o multiprocessing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# MAPREDUCE FOR MATRIX MULTIPLICATION\n",
    "# MAPPER\n",
    "def matrix_multiply_mapper(m, element):\n",
    "    # m: the meet-index.\n",
    "    # element: (matrix-name, i, j, value).\n",
    "    name, i, j, value = element\n",
    "    if name==\"A\":\n",
    "        for k in range(m): # cuz A_ij is relevant for computing C_ik, k=1,..,m.\n",
    "            yield((i,k),(j,value)) # using A's col dimension for meet-indexing.\n",
    "    else:\n",
    "        for k in range(m):\n",
    "            yield((k,j),(i,value)) # using B's row dimension for meet-indexing.\n",
    "# REDUCER\n",
    "def matrix_multiply_reducer(m, key, indexedValues):\n",
    "    #                           ^         ^\n",
    "    #                           |         |\n",
    "    #   expect C's index (e.g. C_ik)    expect (meet-index, value)\n",
    "    resultsByIndex = defaultdict(list)\n",
    "    for index,value in indexedValues:\n",
    "        resultsByIndex[index].append(value)\n",
    "    sumProduct = sum(results[0]*results[1] \n",
    "                     for results in resultsByIndex.values() # results: [valFromA,valueFromB].\n",
    "                     if len(results)==2) # non-meet C_ik cells won't have two values appended.\n",
    "    if sumProduct!=0.0:\n",
    "        yield (key, sumProduct) # key: C's index (e.g. C_ik); sumProduct: C_ik's values.\n",
    "# GENERALIZED MAPREDUCE\n",
    "def map_reduce(inputs, mapper, reducer):\n",
    "    collector = defaultdict(list)\n",
    "    for inpt in inputs:\n",
    "        for key,value in mapper(inpt):\n",
    "            collector[key].append(value)\n",
    "    return [output\n",
    "            for key,values in collector.iteritems()\n",
    "            for output in reducer(key,values)]\n",
    "\n",
    "# USAGE\n",
    "# entries = [(\"A\", 0, 0, 3), (\"A\", 0, 1, 2), (\"B\", 0, 0, 4), (\"B\", 0, 1, -1), (\"B\", 1, 0, 10)]\n",
    "# mapper = partial(matrix_multiply_mapper, 3)\n",
    "# reducer = partial(matrix_multiply_reducer, 3)\n",
    "# map_reduce(entries, mapper, reducer)\n",
    "#    output: [((0, 1), -3), ((0, 0), 32)]\n",
    "#    output in matrix rep.:\n",
    "#    [[32,-3, 0],\n",
    "#     [ 0, 0, 0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "pool2matrices = spNorm + spNormT\n",
    "mapper = partial(matrix_multiply_mapper, len(vocab)) # because the matrix is w2w.\n",
    "reducer = partial(matrix_multiply_reducer, len(vocab)) \n",
    "cosineSimMatrix = map_reduce(pool2matrices, mapper, reducer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### D. K Most-Similar Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "words = ['car','bus','hospital','hotel','gun','bomb','horse','fox','table','bowl','guitar','piano']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# K Most-Similar Retriever for Numpy Matrix Multiplication method\n",
    "from operator import itemgetter\n",
    "def k_most_similar(word, k=10):\n",
    "    cooccurSims = sorted([(otherWord,cosineSimMatrix[wordToIndex[word]][wordToIndex[otherWord]]) \n",
    "                          for otherWord in vocab], key=itemgetter(1), reverse=True)\n",
    "    return cooccurSims[1:k+1] # excluding word itself, which always has 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(u'brabham', 0.41523711928675255),\n",
       " (u'racing', 0.38803851201317202),\n",
       " (u'bugatti', 0.35866012820941412),\n",
       " (u'chassis', 0.27478084309186446),\n",
       " (u'cable', 0.27377935165510164),\n",
       " (u'motors', 0.26590717363846378),\n",
       " (u'aston', 0.26406810403387193),\n",
       " (u'brake', 0.25814992226216038),\n",
       " (u'audi', 0.23974142859235131),\n",
       " (u'motor', 0.23868579179851168)]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k_most_similar('car')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# TODO: MULTIPROCESS W/ MAPREDUCE"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
